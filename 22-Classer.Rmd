# Classer

En plus d'essayer de [regrouper des variables][Décomposer] ensemble, il aussi possible d'essayer de regrouper les participants en groupes. Il s'agit de [l'analyse de classes latentes (LCA)][Classes latentes] et [l'analyse de profils latents (LPA)][Profils latents]. La LCA et la LPA se distinguent par le type de variables qu'elles considèrent, soir les variables continues (LPA) ou catégorielles (LCA). Ces techniques sont utiles lorsque l'expérimentateur souhaite réduire l'échantillon en sous-groupe afin de mieux comprendre les participants. Elles peuvent notamment permettre de décrire les profils de compétences et de difficultés parmi les enfants d'âge préscolaire, en identifiant ceux qui peuvent avoir besoin d'interventions éducatives spécifiques ou encore de décrire des groupes de résilience à la violence conjugale et de mieux orienter les interventions auprès des personnes ayant été victimes d'agressions sexuelles.

Ces analyses issues des modèles de mixture (*mixture modelling*) sont similaires aux techniques de regroupement (*clustering*), mais qui s'en distinguent car elles reposent sur un modèle explicite et prennent en compte le fait que les groupes identifiés sont incertains. Le modèle sous-jacent présenté à la Figure\ \@ref(fig:cla1).

```{r cla1, fig.cap = "Modèle de classes latentes", fig.ext = 'png', cache=TRUE, echo = FALSE, out.height="50%", out.width="50%", fig.align = "center"}
knitr::include_graphics("image//classes1.png")
```

La LCA et la LPA sont considérés comme plus robustes que les autres techniques, comme le *k-mean*, par exemple, par ce qu'elle repose sur un modèles théorique. Cela revient au détriment d'être plus intensif computationnellement, ce qui pourra soulever des problèmes à l'ocassion, surtout pour la LCA. Néanmoins, il demeure que les techniques de regroupement sont en quelque sorte un *bricolage*. Au final, c'est la solution qui fera le plus de sens sur le plan théorique qui sera retenu. Même si les statistiques suggéreront un certain nombre de classes, elles ne seront pas toujours en harmonie entre elles. C'est la simplicité et le pouvoir explicatif qui devra être l'ultime décideur.


## Classes latentes

L'analyse de classes latentes (LCA) permet de partager et de distinguer des sous-groupes non observables (latents) d'individus sur la base de leurs réponses à un ensemble d'indicateurs observables (manifestes) ordinales. Elle fait ainsi partie de la famille des *finite mixture modelling*. Il s'agit d'une analyse **exploratoire** de la même façon que les [analyses factorielles exploratoires]. Elle se distingue d'[analyse factorielle][analyse factorielle exploratoire] qui tente plutôt de regrouper les indicateurs en facteurs (ou groupe), alors que la LCA tente plutôt de regrouper les participants en groupe.


### Installations

Il existe un package permettant de réaliser la LCA avec **R**, soit `poLCA`. Ce package bien qu'excellent pour réaliser la LCA demeure relativement incomplet et mérite quelques amélioration, ce pourquoi le package `poLCAExtra` est recommandé. Installer `poLCAExtra` installera du même coup le package `poLCA`.

```{r ighpe, eval = FALSE}
# Version en développement sur GitHub
remotes::install_github(repo = "quantmeth/poLCAExtra")
```

Une fois téléchargé, comme toujours, il faut appeler le package.

```{r, message = FALSE, warning = FALSE, comment=FALSE}
library(poLCAExtra)
```

### Déterminer le nombre de classes

La première étape est de déterminer le nombre de classes. Pour ce faire, on importe le jeu de données, ici `ex1.poLCA`, un jeu de données de `poLCAEXtra`. On spécifie ensuite le modèle dans une équation.

```{r}
jd <- ex1.poLCA
f1 <- cbind(V1, V2, V3, V4, V5, V6) ~ 1
```

Comme la Figure\ \@ref(fig:cla1) montre, les items sont les variables dépendantes et comme la [MANOVA][MANOVA : analyse de variance multivariée], il faut indiquer ces variables à gauche de l'équation en les liant avec `cbind()`, comme `cbind(V1, V2, V3, V4, V5, V6)`. Le `~` délimite les variables dépendantes et dépendantes. L'utilisation de `1` indique la seule présence d'une constance, il serait possible d'ajouter des covariables pour contrôler des effets dans les variables dépendantes si l'utilisateur le jugeait nécessaire.

Ensuite, il faut rouler différentes valeurs de nombre de classes en incrément de 1.

```{r LCA14, cache=TRUE}
LCA1 <- poLCA(f1, data = jd, nclass = 1, verbose = FALSE) 
LCA2 <- poLCA(f1, data = jd, nclass = 2, verbose = FALSE)
LCA3 <- poLCA(f1, data = jd, nclass = 3, verbose = FALSE)
LCA4 <- poLCA(f1, data = jd, nclass = 4, maxiter = 500, nrep = 4, verbose = FALSE)
```

La fonction `poLCA()` prend en argument le jeu de donnée et la formule et le nombre de classes à rechercher. L'argument `verbose = FALSE` évite de polluer la console avec toutes les sorties de la fonction. Autrement, la fonction sort automatiquement la sortie même s'il y a assignation. Plus il y a de classes, plus le modèles est difficile à évaluer, c'est pourquoi à `nclass = 4`, les options `maxiter` et `nrep` sont ajoutées. Ces arguments augmenteront le nombre maximal d'itération et le nombre de répétions de départ, ce qui permettra d'assurer une meilleur estimation du modèle et aussi une meilleure stabilité. Bien que cela dépend de plusieurs facteurs, ces options deviennent obligatoire vers quatre classes. Et plus le modèle devient compliqué, plus ces valeurs devront augmentées. Il n'y a pas de critères définitifs pour ces valeurs, outre que plus, c'est mieux, mais plus long à calculer.

Pour les comparer, le package `poLCAExtra` permet la comparaison automatique des modèles avec la fonction `anona()`.

```{r}
anova(LCA1, LCA2, LCA3, LCA4)
```

Plus simplement, à l'aide de `poLCAExtra`, ces deux derniers chunks pourraient être remplacés par celui-ci qui tester toutes les classes de `1:4`.

```{r, eval = FALSE}
LCAE <- poLCA(f1, data = jd, nclass = 1:4, maxiter = 500, nrep = 4)
```

Dans cette sortie, plusieurs éléments pourront guidés la décision sur le nombre de classes. Généralement, on recourt au AIC, au BIC et l'entropie relative. Idéalement, il faudrait que le AIC et le BIC soit le plus faible possible avec des bonds importants entre chaque nombre de classes. Dans ce cas-ci ces deux indices commencent à augmenter à `nclass = 4`, ce qui laisse suggérer que trois classes est une bonne solution. Une autre recommandation est une entropie relative supérieure à .80. Il s'agit d'une allant de 0 à 1, le plus haut étant le meilleur. Ici, le modèle à quatre classes n'est pas soutenu. Il faudra jeter une regard à taille des classes afin d'éviter des classes trop petites ou disproportionnées. Cette taille varieront inévitablement d'une question de recherche à l'autre, mais il faut y porter attention. Ici, elle semble toute adéquate pour sauf l'option à deux classes. un dernier test souvent utilisé est le test de vraisemblance de Lo-Mendell-Rubin (LMR) qui fournit une valeur-*p*. Ce test suggère un nombre de classes jusqu'au premier modèle non-significatif (exclusivement). Ici, le LMR suggère trois classes, car la quatrième classes est non-significative au seuil de 5%. Ce test a tendance a être très libéral, il faut y recourir avec discernement.

### Inspections


```{r}
poLCA.tech10(LCA3)
```

En plus de 

### Représentations graphiques

```{r lcaplot, fig.cap="Analyse visuelle des classes",fig.align="center", out.height='75%', out.width='75%'}
plot(LCA3)
```

Une autre façon de présenter les dnn.es

```{r testjitter,fig.cap="Analyse visuelle supplémentaire des classes",fig.align="center", out.height='75%', out.width='75%'}
#library(tidyverse)
#jdtest <- LCAE$LCA[[3]]$y
jdtest <- LCA3$y
v <- (colnames(jdtest))
jdtest$Classes <- as.factor(predict(LCA3)$Pred)

jdtest <- jdtest %>% 
  gather(key = "Variable", value = "Value", -Classes) 


jds <- jdtest %>% 
  group_by(Classes, Variable) %>% 
  summarise(y = mean(Value), 
            se = sd(Value)/sqrt(n()), 
            ymin = y - 1.96*se, 
            ymax = y + 1.96*se,
            Value = y)


jdtest %>%  
  ggplot(aes(x = Variable, y = Value, fill = Classes, group = Classes, color = Classes)) + 
  geom_jitter(alpha = .1) +
  geom_point(jds, mapping = aes(x = Variable, y = y)) + 
  geom_errorbar(jds, mapping = aes(ymin = ymin, ymax = ymax), alpha = 1) + theme_minimal()
```


### Analyses supplémentaires


```{r r3stepcode, cache = TRUE}
res.r3 <- r3step("continuous", LCA3)
```


```{r r3step, fig.cap="r3step des classes",fig.align="center", out.height='75%', out.width='75%'}
plot(res.r3)
```


```{r d3stepcode, cache = TRUE}
res.d3 <- d3step("categorical", LCA3)
```


```{r d3step, fig.cap="r3step des classes",fig.align="center", out.height='75%', out.width='75%'}
plot(res.d3)
```


### Quelques fonctions utiles

Une fois l'analyse terminée, rouler une dernière fois avec une [graine][les graines] et les arguments `nrep` et `maxiter`.

## Profils latents

Les packages suivants sont nécessaires


```{r packlpa, message = FALSE, warning=FALSE}
# install.packages('dplyr')
# install.packages('tidyLPA')
library(dplyr)
library(tidyLPA)
```


Effectuer l'analyse de profils latents. Pour ce faire, il faut sélectionner les variables pour l'analyse avec la fonction *select*. Dans la fonction *estimate_profiles*, spécifier combien de profils investigués. 

```{r runlpa}
jd <- ex3.tidyLPA

jd %>%
  select(V1, V2, V3, V4, V5) %>%
  estimate_profiles(1:5) 
```

Il est possible de générer des graphiques pour comparer certains indices d'ajustement, notamment l'AIC, le BIC et l'entropie à l'aide de la fonction *plot*. 
```{r plotstatlpa, eval = FALSE}
lpa1_5 <- jd %>%
  select(V1, V2, V3, V4, V5) %>%
  estimate_profiles(1:5) 


plot(lpa1_5, statistics = 'AIC')
plot(lpa1_5, statistics = 'BIC')
plot(lpa1_5, statistics = 'Entropy')
```

Pour déterminer le nombre de participants (*n*) dans chaque profil, procéder ainsi. 

```{r lpa3}
LPA3 <- jd %>%
  select(V1, V2, V3, V4, V5) %>%
  estimate_profiles(3)
```



```{r getprop}
get_data(LPA3) %>% 
  group_by(Class) %>% 
  count()
```

Finalement, générer la représentation graphique du modèle choisi (et des autres modèles si besoin) à l'aide de la fonction *plot_profiles*.

```{r lpaplot, fig.cap="Analyse visuelle des profils",fig.align="center", out.height='75%', out.width='75%'}
LPA3 %>%
  plot_profiles()
```

Différents type de modèles possibles

```{r}
LPAmodel <- data.frame(Model = 1:6,
                       Variance = c("equal","varying"),
                       Covariance = rep(c("zero","equal","varying"), 
                                        each = 2))


#LPAmodel



kbl(LPAmodel, align = "c", booktabs=TRUE, caption = "Différents type de modèles possibles") %>%
  kable_classic(full_width = FALSE)  %>%
  kable_styling(position = "center", latex_options = "HOLD_position")

```


